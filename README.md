# Amazon_web_scraping
Scraping products info from amazon

WORKFLOW

--> Install the webriver

--> Start the webdriver

--> Get the page_source from the url

--> extract using BeautifulSoup

--> make a prototype

--> generalize the prototype

--> extract relevant fields using unique identifiers such as class , id , regex etc..

--> from the url of each single product , extract other additional fields

--> finally , write the results to a CSV file

--> program can be run by installing the necessary packages in google colab ( code already written ) and calling the get_complete_data() function
